<!doctype html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <title>WebGPU Subgroup Matrix</title>
</head>

<body>
    <pre id="output"></pre>

    <script>
        // Problem size
        // We are working on square matrices here
        const MATRIX_SIZE = 1024;

        // Logical tile size in X/Y direction
        // Basically, you want to use HW tiles to compute the logical tile for each workgroup
        //
        const BLOCK_M = 16; // logical C tile rows per workgroup
        const BLOCK_N = 16;

        const K_STEP = 16; // multiple of 'SUB_K', affect the shared memory usage

        // HW specific, for Apple M4, it's 8x8
        // (M, K) x (K, N)
        const SUB_M = 8;
        const SUB_N = 8;
        const SUB_K = 8;

        // Let's call these "WORKGROUP_SIZE_X", "WORKGROUP_SIZE_Y"
        // Limitations:
        // (1) WORKGROUP_SIZE_X must be a multiple of 64
        // (2) WORKGROUP_SIZE_X * WORKGROUP_SIZE_Y <= 256
        // The only valid workgroup sizes are:
        // @workgroup_size(64, 1, 1)     // 64 threads
        // @workgroup_size(64, 2, 1)     // 128 threads  
        // @workgroup_size(64, 4, 1)     // 256 threads
        // @workgroup_size(128, 1, 1)    // 128 threads
        // @workgroup_size(128, 2, 1)    // 256 threads
        // @workgroup_size(256, 1, 1)    // 256 threads
        const WORKGROUP_SIZE_X = 64;
        const WORKGROUP_SIZE_Y = 1;

        function log(...args) {
            document.getElementById("output").textContent += args.join(" ") + "\n";
        }

        function printMatrix(A, rows, cols, verbose = false) {
            if (verbose) {
                // Print full matrix
                for (let i = 0; i < rows; i++) {
                    let row = [];
                    for (let j = 0; j < cols; j++) {
                        row.push(A[i * cols + j]);
                    }
                    log(row.join(" "));
                }
            } else {
                // Print abbreviated matrix with ellipsis
                for (let i = 0; i < rows; i++) {
                    if (i < 3 || i > rows - 4) {
                        let row = [];
                        for (let j = 0; j < cols; j++) {
                            if (j < 3 || j > cols - 4) {
                                row.push(A[i * cols + j]);
                            } else if (j === 3) {
                                row.push("...");
                            }
                        }
                        log(row.join(" "));
                    } else if (i === 3) {
                        log("...");
                    }
                }
            }
        }

        async function cpuImplementation(A, B, C, matrix_size) {
            const num_threads = navigator.hardwareConcurrency || 4;
            let start = performance.now();

            // Create worker code as a blob
            const workerCode = `
                self.onmessage = function(e) {
                    const { A, B, matrix_size, startRow, endRow } = e.data;
                    const localC = new Float16Array(matrix_size * matrix_size);
                    
                    for (let i = startRow; i < endRow; i++) {
                        for (let j = 0; j < matrix_size; j++) {
                            localC[i * matrix_size + j] = 0;
                            for (let k = 0; k < matrix_size; k++) {
                                localC[i * matrix_size + j] += A[i * matrix_size + k] * B[k * matrix_size + j];
                            }
                        }
                    }
                    
                    self.postMessage({ localC, startRow, endRow });
                };
            `;

            const workerBlob = new Blob([workerCode], { type: 'application/javascript' });
            const workerUrl = URL.createObjectURL(workerBlob);

            // Calculate rows per thread
            const rowsPerThread = Math.ceil(matrix_size / num_threads);
            const workers = [];
            const promises = [];

            // Create and start workers
            for (let i = 0; i < num_threads; i++) {
                const startRow = i * rowsPerThread;
                const endRow = Math.min((i + 1) * rowsPerThread, matrix_size);

                if (startRow >= matrix_size) break;

                const worker = new Worker(workerUrl);
                workers.push(worker);

                const promise = new Promise((resolve) => {
                    worker.onmessage = function (e) {
                        const { localC, startRow, endRow } = e.data;
                        // Copy results to main array
                        for (let row = startRow; row < endRow; row++) {
                            for (let col = 0; col < matrix_size; col++) {
                                C[row * matrix_size + col] = localC[row * matrix_size + col];
                            }
                        }
                        resolve();
                    };
                });
                promises.push(promise);

                worker.postMessage({ A, B, matrix_size, startRow, endRow });
            }

            // Wait for all workers to complete
            await Promise.all(promises);

            // Clean up workers
            workers.forEach(worker => worker.terminate());
            URL.revokeObjectURL(workerUrl);

            let end = performance.now();

            log("\nCPU Took: " + (end - start) + "ms");
            log("Used " + workers.length + " threads");

            printMatrix(C, matrix_size, matrix_size);
            return C;
        }

        function calculateMSE(cpuResult, gpuResult, size) {
            let mse = 0;
            let numElements = size * size;

            for (let i = 0; i < numElements; i++) {
                let error = cpuResult[i] - gpuResult[i];
                mse += error * error;
            }

            mse /= numElements;
            return mse;
        }

        async function run(device) {
            const computeShader = `
                enable chromium_experimental_subgroup_matrix;
                enable f16;

                @group(0) @binding(0) var<storage, read>        A : array<f16>;
                @group(0) @binding(1) var<storage, read>        B : array<f16>;
                @group(0) @binding(2) var<storage, read_write>  C : array<f16>;

                // ---- Shapes / Tunables ----
                const MAT_SIZE  : u32 = ${MATRIX_SIZE}u;  // Problem size

                const BLOCK_M   : u32 = ${BLOCK_M}u;    // logical C tile rows per workgroup
                const BLOCK_N   : u32 = ${BLOCK_N}u;    // logical C tile cols per workgroup
                const K_STEP    : u32 = ${K_STEP}u;    // K chunk per outer loop (multiple of SUB_K)

                const SUB_M     : u32 = ${SUB_M}u;     // HW tile M
                const SUB_N     : u32 = ${SUB_N}u;     // HW tile N
                const SUB_K     : u32 = ${SUB_K}u;     // HW tile K for MMA

                const kColMajor : bool = false; // row-major layout; stride is MAT_SIZE

                // Workgroup (shared) tiles, linearized
                // According to Tyler's code
                //
                const AS_ELEMS  : u32 = BLOCK_M  * K_STEP;   
                const BS_ELEMS  : u32 = K_STEP   * BLOCK_N; 
                var<workgroup> Asub : array<f16, AS_ELEMS>;
                var<workgroup> Bsub : array<f16, BS_ELEMS>;

                // ---- Helpers ----
                fn idx2D(row : u32, col : u32, stride : u32) -> u32 {
                    return row * stride + col;
                }

                // ---- Kernel ----
                @compute @workgroup_size(${WORKGROUP_SIZE_X}, ${WORKGROUP_SIZE_Y}, 1)
                fn main(
                    @builtin(workgroup_id)           wg_id  : vec3<u32>,
                    @builtin(local_invocation_index) lidx   : u32,
                ) {
                let blockRow : u32 = wg_id.y * BLOCK_M;
                let blockCol : u32 = wg_id.x * BLOCK_N;

                var acc00 : subgroup_matrix_result<f16, SUB_M, SUB_N>;
                var acc01 : subgroup_matrix_result<f16, SUB_M, SUB_N>;
                var acc10 : subgroup_matrix_result<f16, SUB_M, SUB_N>;
                var acc11 : subgroup_matrix_result<f16, SUB_M, SUB_N>;

                for (var k0 : u32 = 0u; k0 < MAT_SIZE; k0 += K_STEP) {

                    // ---- Cooperative load A(blockRow..+15, k0..+K_STEP-1) into Asub ----
                    var t : u32 = lidx;
                    loop {
                        if (t >= AS_ELEMS) { break; }
                        let a_r : u32 = t / K_STEP;  // 0..BLOCK_M-1
                        let a_c : u32 = t % K_STEP;  // 0..K_STEP-1
                        let g_r : u32 = blockRow + a_r;
                        let g_c : u32 = k0 + a_c;

                        if (g_r < MAT_SIZE && g_c < MAT_SIZE) {
                            Asub[t] = A[idx2D(g_r, g_c, MAT_SIZE)];
                        } else {
                            Asub[t] = f16(0.0);
                        }

                        t += 64u; // advance by workgroup size (64 lanes here)
                    }

                    // ---- Cooperative load B(k0..+K_STEP-1, blockCol..+15) into Bsub ----
                    t = lidx;
                    loop {
                        if (t >= BS_ELEMS) { break; }
                        let b_r : u32 = t / BLOCK_N; // 0..K_STEP-1
                        let b_c : u32 = t % BLOCK_N; // 0..BLOCK_N-1
                        let g_r : u32 = k0 + b_r;
                        let g_c : u32 = blockCol + b_c;

                        if (g_r < MAT_SIZE && g_c < MAT_SIZE) {
                            Bsub[t] = B[idx2D(g_r, g_c, MAT_SIZE)];
                        } else {
                            Bsub[t] = f16(0.0);
                        }

                        t += 64u;
                    }

                    workgroupBarrier();

                    // ---- Compute: for this K_STEP, walk in SUB_K and issue 4x 8x8 MMAs ----
                    for (var kk : u32 = 0u; kk < K_STEP; kk += SUB_K) {

                        // TL quadrant: A[0..7, kk..kk+SUB_K-1] x B[kk..kk+SUB_K-1, 0..7]
                        let a_off_tl : u32 = idx2D(0u,  kk, K_STEP);
                        let b_off_tl : u32 = idx2D(kk, 0u,  BLOCK_N);
                        let L_tl = subgroupMatrixLoad<subgroup_matrix_left<f16, SUB_M, SUB_K>>(&Asub, a_off_tl, kColMajor, K_STEP);
                        let R_tl = subgroupMatrixLoad<subgroup_matrix_right<f16, SUB_K, SUB_N>>(&Bsub, b_off_tl, kColMajor, BLOCK_N);
                        acc00 = subgroupMatrixMultiplyAccumulate(L_tl, R_tl, acc00);

                        // TR quadrant: A[0..7, kk..] x B[kk.., 8..15]
                        let b_off_tr : u32 = idx2D(kk, 8u, BLOCK_N);
                        let R_tr = subgroupMatrixLoad<subgroup_matrix_right<f16, SUB_K, SUB_N>>(&Bsub, b_off_tr, kColMajor, BLOCK_N);
                        acc01 = subgroupMatrixMultiplyAccumulate(L_tl, R_tr, acc01);

                        // BL quadrant: A[8..15, kk..] x B[kk.., 0..7]
                        let a_off_bl : u32 = idx2D(8u, kk, K_STEP);
                        let L_bl = subgroupMatrixLoad<subgroup_matrix_left<f16, SUB_M, SUB_K>>(&Asub, a_off_bl, kColMajor, K_STEP);
                        acc10 = subgroupMatrixMultiplyAccumulate(L_bl, R_tl, acc10);

                        // BR quadrant: A[8..15, kk..] x B[kk.., 8..15]
                        acc11 = subgroupMatrixMultiplyAccumulate(L_bl, R_tr, acc11);

                    }

                    workgroupBarrier(); // safe to overwrite Asub/Bsub in next iteration
                }

                // ---- Store back the four 8x8 quadrants to C ----
                let c_off00 : u32 = idx2D(blockRow + 0u, blockCol + 0u, MAT_SIZE);
                subgroupMatrixStore(&C, c_off00, acc00, kColMajor, MAT_SIZE);

                let c_off01 : u32 = idx2D(blockRow + 0u, blockCol + 8u, MAT_SIZE);
                subgroupMatrixStore(&C, c_off01, acc01, kColMajor, MAT_SIZE);

                let c_off10 : u32 = idx2D(blockRow + 8u, blockCol + 0u, MAT_SIZE);
                subgroupMatrixStore(&C, c_off10, acc10, kColMajor, MAT_SIZE);

                let c_off11 : u32 = idx2D(blockRow + 8u, blockCol + 8u, MAT_SIZE);
                subgroupMatrixStore(&C, c_off11, acc11, kColMajor, MAT_SIZE);
                }
            `;

            log(computeShader);

            // Calculate grid dimensions based on global constants
            const GRID_X = MATRIX_SIZE / BLOCK_N;
            const GRID_Y = MATRIX_SIZE / BLOCK_M;

            const A = new Float16Array(MATRIX_SIZE * MATRIX_SIZE);
            const B = new Float16Array(MATRIX_SIZE * MATRIX_SIZE);
            const C = new Float16Array(MATRIX_SIZE * MATRIX_SIZE);

            for (let i = 0; i < MATRIX_SIZE * MATRIX_SIZE; i++) {
                A[i] = Math.random() / 10.0;
                // A[i] = 1.0;
            }

            // B is identity matrix
            for (let i = 0; i < MATRIX_SIZE * MATRIX_SIZE; i++) {
                const row = Math.floor(i / MATRIX_SIZE);
                const col = i % MATRIX_SIZE;
                B[i] = (row === col) ? 1.0 : 0.0;
            }

            for (let i = 0; i < MATRIX_SIZE * MATRIX_SIZE; i++) {
                C[i] = 0;
            }

            const A_Buffer = device.createBuffer({
                size: A.byteLength,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            });

            const B_Buffer = device.createBuffer({
                size: B.byteLength,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            });

            const C_Buffer = device.createBuffer({
                size: C.byteLength,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
            });

            // Create staging buffer for reading results
            const stagingBuffer = device.createBuffer({
                size: C.byteLength,
                usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
            });

            device.queue.writeBuffer(A_Buffer, 0, A);
            device.queue.writeBuffer(B_Buffer, 0, B);

            // Create compute pipeline
            const computePipeline = device.createComputePipeline({
                layout: "auto",
                compute: {
                    module: device.createShaderModule({
                        code: computeShader,
                    }),
                    entryPoint: "main",
                },
            });

            // Create bind group

            const bindGroup = device.createBindGroup({
                layout: computePipeline.getBindGroupLayout(0),
                entries: [
                    {
                        binding: 0,
                        resource: { buffer: A_Buffer },
                    },
                    {
                        binding: 1,
                        resource: { buffer: B_Buffer },
                    },
                    {
                        binding: 2,
                        resource: { buffer: C_Buffer },
                    },
                ],
            });

            // Warmup: Run the kernel once without timing
            log("Warming up GPU kernel...");
            const warmupCommandEncoder = device.createCommandEncoder();
            const warmupComputePass = warmupCommandEncoder.beginComputePass();
            warmupComputePass.setPipeline(computePipeline);
            warmupComputePass.setBindGroup(0, bindGroup);
            warmupComputePass.dispatchWorkgroups(GRID_X, GRID_Y);
            warmupComputePass.end();

            const warmupCommandBuffer = warmupCommandEncoder.finish();
            device.queue.submit([warmupCommandBuffer]);
            await device.queue.onSubmittedWorkDone();
            log("Warmup completed.");

            // Now run the actual timed execution
            const commandEncoder = device.createCommandEncoder();
            const computePass = commandEncoder.beginComputePass();
            computePass.setPipeline(computePipeline);
            computePass.setBindGroup(0, bindGroup);

            // Dispatch the compute shader
            computePass.dispatchWorkgroups(GRID_X, GRID_Y);
            computePass.end();

            // Copy output to staging buffer for reading
            commandEncoder.copyBufferToBuffer(
                C_Buffer,
                0,
                stagingBuffer,
                0,
                C.byteLength,
            );

            // Submit and wait for GPU execution
            const commandBuffer = commandEncoder.finish();
            device.queue.submit([commandBuffer]);

            let start = performance.now();

            await device.queue.onSubmittedWorkDone();

            let end = performance.now();

            log(
                "\nCompute shader executed successfully on GPU! " +
                (end - start) +
                "ms",
            );

            // Map and read the results
            await stagingBuffer.mapAsync(GPUMapMode.READ);
            const results = new Float16Array(stagingBuffer.getMappedRange());

            // Copy the data before unmapping to avoid detached ArrayBuffer
            const resultsCopy = new Float16Array(results);
            stagingBuffer.unmap();

            printMatrix(resultsCopy, MATRIX_SIZE, MATRIX_SIZE);

            // Run CPU implementation and get results
            const cpuResult = new Float16Array(MATRIX_SIZE * MATRIX_SIZE);
            await cpuImplementation(A, B, cpuResult, MATRIX_SIZE);

            // Calculate Mean Square Error
            const mse = calculateMSE(cpuResult, resultsCopy, MATRIX_SIZE);
            log("\n=== COMPARISON RESULTS ===");
            log("Mean Square Error (MSE):", mse.toFixed(8));
            log("Root Mean Square Error (RMSE):", Math.sqrt(mse).toFixed(8));
            log("================================\n");
        }

        async function main() {
            if (!navigator.gpu?.requestAdapter) {
                log("WebGPU is NOT available in this browser.");
                return;
            }

            const adapter = await navigator.gpu.requestAdapter();
            if (!adapter) {
                log("No GPU adapter found.");
                return;
            }

            log("Adapter found: " + (adapter.info.description || "Unnamed GPU"));

            const requiredFeatures = [
                "chromium-experimental-subgroup-matrix",
                "shader-f16",
            ];

            if (!requiredFeatures.every((f) => adapter.features.has(f))) {
                log("Missing required features:", requiredFeatures.join(", "));
                return;
            }

            const device = await adapter.requestDevice({ requiredFeatures });
            log("Running...");
            await run(device);
        }

        main();
    </script>
</body>

</html>