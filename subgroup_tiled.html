<!doctype html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <title>WebGPU Subgroup Matrix</title>
</head>

<body>
    <pre id="output"></pre>

    <script>
        function log(...args) {
            document.getElementById("output").textContent += args.join(" ") + "\n";
        }

        function printMatrix(A, rows, cols, verbose = false) {
            if (verbose) {
                // Print full matrix
                for (let i = 0; i < rows; i++) {
                    let row = [];
                    for (let j = 0; j < cols; j++) {
                        row.push(A[i * cols + j]);
                    }
                    log(row.join(" "));
                }
            } else {
                // Print abbreviated matrix with ellipsis
                for (let i = 0; i < rows; i++) {
                    if (i < 3 || i > rows - 4) {
                        let row = [];
                        for (let j = 0; j < cols; j++) {
                            if (j < 3 || j > cols - 4) {
                                row.push(A[i * cols + j]);
                            } else if (j === 3) {
                                row.push("...");
                            }
                        }
                        log(row.join(" "));
                    } else if (i === 3) {
                        log("...");
                    }
                }
            }
        }

        function cpuImplementation(A, B, C) {
            let start = performance.now();

            for (let i = 0; i < 16; i++) {
                for (let j = 0; j < 16; j++) {
                    C[i * 16 + j] = 0;
                    for (let k = 0; k < 16; k++) {
                        C[i * 16 + j] += A[i * 16 + k] * B[k * 16 + j];
                    }
                }
            }

            let end = performance.now();

            log("\nCPU Took: " + (end - start) + "ms");

            printMatrix(C, 16, 16);
            return C;
        }

        function calculateMSE(cpuResult, gpuResult, size) {
            let mse = 0;
            let numElements = size * size;

            for (let i = 0; i < numElements; i++) {
                let error = cpuResult[i] - gpuResult[i];
                mse += error * error;
            }

            mse /= numElements;
            return mse;
        }

        async function run(device) {
            // We assume square matrix for now

            // N = number of columns/rows in the full matrix (your stride)
            // e.g.,
            // A,B are 16x16, then N = 16

            // TILE_SIZE = hardware specific in X/Y direction
            // e.g.,
            // TILE_SIZE = 8, Apple M4

            // in above example,
            // our tile_row will iterate from 0 to 1 (two tiles in Y)
            // our tile_col will iterate from 0 to 1 (two tiles in X)

            // offsets should be (tile_row * N * TILE_SIZE) + (tile_col * TILE_SIZE);
            // tile(0, 0) = 0 * 16 * 8 + 0 * 8 = 0
            // tile(0, 1) = 0 * 16 * 8 + 1 * 8 = 8
            // tile(1, 0) = 1 * 16 * 8 + 0 * 8 = 128
            // tile(1, 1) = 1 * 16 * 8 + 1 * 8 = 136

            const computeShader = `
                enable chromium_experimental_subgroup_matrix;
                enable f16;

                @group(0) @binding(0) var<storage, read>        A : array<f16>;
                @group(0) @binding(1) var<storage, read>        B : array<f16>;
                @group(0) @binding(2) var<storage, read_write>  C : array<f16>;

                // var<workgroup> a_shared : array<f16, 8>;
                // var<workgroup> b_shared : array<f16, 8>;
                    
                const kColMajor : bool = false;  
                const kStride   : u32  = 16u;     

                @compute @workgroup_size(64, 1, 1)
                fn main(
                    @builtin(global_invocation_id) gid : vec3<u32>,
                    @builtin(subgroup_id) sid : u32,
                ) {
                    const offset = 0;

                    const N : u32 = 16u;
                    const TILE_SIZE : u32 = 8u;

                    // inferred from above, N / TILE_SIZE
                    const TILES_Y : u32 = 2u; 
                    const TILES_X : u32 = 2u;
                    const TILES_K : u32 = 2u;

                    for (var tile_row = 0u; tile_row < TILES_Y; tile_row++) {
                        for (var tile_col = 0u; tile_col < TILES_X; tile_col++) {

                            var ACC : subgroup_matrix_result<f16, 8, 8>;

                            for (var k_tile = 0u; k_tile < TILES_K; k_tile++) {

                                // Load A tile: A[tile_row, k_tile]
                                let a_offset = u32(tile_row * N * TILE_SIZE + k_tile * TILE_SIZE);
                                var L = subgroupMatrixLoad<subgroup_matrix_left<f16, 8, 8>>(&A, a_offset, kColMajor, N);

                                // Load B tile: B[k_tile, tile_col]
                                let b_offset = u32(k_tile * N * TILE_SIZE + tile_col * TILE_SIZE);
                                var R = subgroupMatrixLoad<subgroup_matrix_right<f16, 8, 8>>(&B, b_offset, kColMajor, N);

                                ACC = subgroupMatrixMultiplyAccumulate(L, R, ACC);
                            }

                            // Store the result
                            let c_offset = u32(tile_row * N * TILE_SIZE) + u32(tile_col * TILE_SIZE);
                            subgroupMatrixStore(&C, c_offset, ACC, kColMajor, N);

                        }
                    }
                }
            `;

            log(computeShader);

            // if each tile is 8x8, then
            // let's prepare 16x16 matrix for A, B, C
            const A = new Float16Array(16 * 16); // 2 tiles in X, 2 tiles in Y
            const B = new Float16Array(16 * 16); // 2 tiles in X, 2 tiles in Y
            const C = new Float16Array(16 * 16); // 2 tiles in X, 2 tiles in Y

            for (let i = 0; i < 16 * 16; i++) {
                A[i] = Math.random();
                // A[i] = 1.0;
            }

            for (let i = 0; i < 16 * 16; i++) {
                // B[i] = 1.0;
                B[i] = Math.random();
            }

            for (let i = 0; i < 16 * 16; i++) {
                C[i] = 0;
            }

            const A_Buffer = device.createBuffer({
                size: A.byteLength,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            });

            const B_Buffer = device.createBuffer({
                size: B.byteLength,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
            });

            const C_Buffer = device.createBuffer({
                size: C.byteLength,
                usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
            });

            // Create staging buffer for reading results
            const stagingBuffer = device.createBuffer({
                size: C.byteLength,
                usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
            });

            device.queue.writeBuffer(A_Buffer, 0, A);
            device.queue.writeBuffer(B_Buffer, 0, B);

            // Create compute pipeline
            const computePipeline = device.createComputePipeline({
                layout: "auto",
                compute: {
                    module: device.createShaderModule({
                        code: computeShader,
                    }),
                    entryPoint: "main",
                },
            });

            // Create bind group

            const bindGroup = device.createBindGroup({
                layout: computePipeline.getBindGroupLayout(0),
                entries: [
                    {
                        binding: 0,
                        resource: { buffer: A_Buffer },
                    },
                    {
                        binding: 1,
                        resource: { buffer: B_Buffer },
                    },
                    {
                        binding: 2,
                        resource: { buffer: C_Buffer },
                    },
                ],
            });

            // Warmup: Run the kernel once without timing
            log("Warming up GPU kernel...");
            const warmupCommandEncoder = device.createCommandEncoder();
            const warmupComputePass = warmupCommandEncoder.beginComputePass();
            warmupComputePass.setPipeline(computePipeline);
            warmupComputePass.setBindGroup(0, bindGroup);
            warmupComputePass.dispatchWorkgroups(1);
            warmupComputePass.end();

            const warmupCommandBuffer = warmupCommandEncoder.finish();
            device.queue.submit([warmupCommandBuffer]);
            await device.queue.onSubmittedWorkDone();
            log("Warmup completed.");

            // Now run the actual timed execution
            const commandEncoder = device.createCommandEncoder();
            const computePass = commandEncoder.beginComputePass();
            computePass.setPipeline(computePipeline);
            computePass.setBindGroup(0, bindGroup);

            // Dispatch the compute shader
            computePass.dispatchWorkgroups(1);
            computePass.end();

            // Copy output to staging buffer for reading
            commandEncoder.copyBufferToBuffer(
                C_Buffer,
                0,
                stagingBuffer,
                0,
                C.byteLength,
            );

            // Submit and wait for GPU execution
            const commandBuffer = commandEncoder.finish();
            device.queue.submit([commandBuffer]);

            let start = performance.now();

            await device.queue.onSubmittedWorkDone();

            let end = performance.now();

            log(
                "\nCompute shader executed successfully on GPU! " +
                (end - start) +
                "ms",
            );

            // Map and read the results
            await stagingBuffer.mapAsync(GPUMapMode.READ);
            const results = new Float16Array(stagingBuffer.getMappedRange());

            // Copy the data before unmapping to avoid detached ArrayBuffer
            const resultsCopy = new Float16Array(results);
            stagingBuffer.unmap();

            printMatrix(resultsCopy, 16, 16);

            // Run CPU implementation and get results
            const cpuResult = new Float16Array(16 * 16);
            cpuImplementation(A, B, cpuResult);

            // Calculate Mean Square Error
            const mse = calculateMSE(cpuResult, resultsCopy, 16);
            log("\n=== COMPARISON RESULTS ===");
            log("Mean Square Error (MSE):", mse.toFixed(8));
            log("Root Mean Square Error (RMSE):", Math.sqrt(mse).toFixed(8));
            log("================================\n");
        }

        async function main() {
            if (!navigator.gpu?.requestAdapter) {
                log("WebGPU is NOT available in this browser.");
                return;
            }

            const adapter = await navigator.gpu.requestAdapter();
            if (!adapter) {
                log("No GPU adapter found.");
                return;
            }

            log("Adapter found: " + (adapter.info.description || "Unnamed GPU"));

            const requiredFeatures = [
                "chromium-experimental-subgroup-matrix",
                "shader-f16",
            ];

            if (!requiredFeatures.every((f) => adapter.features.has(f))) {
                log("Missing required features:", requiredFeatures.join(", "));
                return;
            }

            const device = await adapter.requestDevice({ requiredFeatures });
            log("Running...");
            await run(device);
        }

        main();
    </script>
</body>

</html>